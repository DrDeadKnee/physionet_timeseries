{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "blank-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "collaborative-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>SepsisEver</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.200</td>\n",
       "      <td>135.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>24.382587</td>\n",
       "      <td>...</td>\n",
       "      <td>194.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.200</td>\n",
       "      <td>135.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>24.382587</td>\n",
       "      <td>...</td>\n",
       "      <td>194.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.225</td>\n",
       "      <td>127.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>24.382587</td>\n",
       "      <td>...</td>\n",
       "      <td>194.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.250</td>\n",
       "      <td>119.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>24.382587</td>\n",
       "      <td>...</td>\n",
       "      <td>194.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.275</td>\n",
       "      <td>119.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>-0.441724</td>\n",
       "      <td>24.382587</td>\n",
       "      <td>...</td>\n",
       "      <td>194.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-12.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429849</th>\n",
       "      <td>88.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>37.300</td>\n",
       "      <td>126.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>26.680000</td>\n",
       "      <td>...</td>\n",
       "      <td>81.96</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-19.52</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429850</th>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>37.400</td>\n",
       "      <td>118.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>26.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.72</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-19.52</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429851</th>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.400</td>\n",
       "      <td>143.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>26.840000</td>\n",
       "      <td>...</td>\n",
       "      <td>83.48</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-19.52</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429852</th>\n",
       "      <td>95.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>37.600</td>\n",
       "      <td>129.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.24</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-19.52</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429853</th>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>37.700</td>\n",
       "      <td>106.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.017979</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>85.00</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-19.52</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1429854 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HR  O2Sat    Temp    SBP    MAP   DBP  Resp      EtCO2  BaseExcess  \\\n",
       "0        60.0   98.0  36.200  135.0  109.0  72.0  17.0  33.017979   -0.441724   \n",
       "1        60.0   98.0  36.200  135.0  109.0  72.0  17.0  33.017979   -0.441724   \n",
       "2        56.0   98.0  36.225  127.0  105.0  73.0  15.0  33.017979   -0.441724   \n",
       "3        54.0   98.0  36.250  119.0  100.0  76.0  13.0  33.017979   -0.441724   \n",
       "4        52.0   98.0  36.275  119.0   87.0  67.0  12.0  33.017979   -0.441724   \n",
       "...       ...    ...     ...    ...    ...   ...   ...        ...         ...   \n",
       "1429849  88.0   95.0  37.300  126.0   82.0  61.0  15.0  33.017979    0.800000   \n",
       "1429850  88.0   98.0  37.400  118.0   75.0  57.0  20.0  33.017979    1.600000   \n",
       "1429851  92.0   96.0  37.400  143.0   96.0  70.0  13.0  33.017979    2.400000   \n",
       "1429852  95.0   96.0  37.600  129.0   84.0  61.0  15.5  33.017979    3.200000   \n",
       "1429853  92.0   95.0  37.700  106.0   68.0  51.0  10.0  33.017979    4.000000   \n",
       "\n",
       "              HCO3  ...  Platelets   Age  Gender     Unit1     Unit2  \\\n",
       "0        24.382587  ...     194.00  57.0     0.0  0.492043  0.507957   \n",
       "1        24.382587  ...     194.00  57.0     0.0  0.492043  0.507957   \n",
       "2        24.382587  ...     194.00  57.0     0.0  0.492043  0.507957   \n",
       "3        24.382587  ...     194.00  57.0     0.0  0.492043  0.507957   \n",
       "4        24.382587  ...     194.00  57.0     0.0  0.492043  0.507957   \n",
       "...            ...  ...        ...   ...     ...       ...       ...   \n",
       "1429849  26.680000  ...      81.96  76.7     0.0  0.000000  1.000000   \n",
       "1429850  26.760000  ...      82.72  76.7     0.0  0.000000  1.000000   \n",
       "1429851  26.840000  ...      83.48  76.7     0.0  0.000000  1.000000   \n",
       "1429852  26.920000  ...      84.24  76.7     0.0  0.000000  1.000000   \n",
       "1429853  27.000000  ...      85.00  76.7     0.0  0.000000  1.000000   \n",
       "\n",
       "         HospAdmTime  ICULOS  SepsisLabel  SepsisEver     id  \n",
       "0             -12.02     1.0          0.0           0  27338  \n",
       "1             -12.02     2.0          0.0           0  27338  \n",
       "2             -12.02     3.0          0.0           0  27338  \n",
       "3             -12.02     4.0          0.0           0  27338  \n",
       "4             -12.02     5.0          0.0           0  27338  \n",
       "...              ...     ...          ...         ...    ...  \n",
       "1429849       -19.52    39.0          0.0           0  18000  \n",
       "1429850       -19.52    40.0          0.0           0  18000  \n",
       "1429851       -19.52    41.0          0.0           0  18000  \n",
       "1429852       -19.52    42.0          0.0           0  18000  \n",
       "1429853       -19.52    43.0          0.0           0  18000  \n",
       "\n",
       "[1429854 rows x 43 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = \"/h/dsmith/physionet_data/preppedf/physionet_data.parquet\"\n",
    "df = pd.read_parquet(fin, engine=\"pyarrow\")\n",
    "npts = 10\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hungry-woman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyarrow import ArrowInvalid\\nimport pyarrow as pa\\nimport pyarrow.parquet as pq\\n\\ncols = pd.DataFrame()\\nnewpath = \\'/h/dsmith/physionet_data/preppedg/physionet_data.parquet\\'\\n\\nfor i in os.listdir(fin):\\n    fullpath = os.path.join(fin, i)\\n    df = pd.read_parquet(fullpath)\\n    df[\"SepsisEver\"] = df[\"SepsisEver\"].replace(0.1, 1).astype(int)\\n    table = pa.table(df)\\n    pq.write_to_dataset(table, newpath)\\n    types = df.dtypes.to_dict()\\n    types[\"file\"] = i\\n    cols = cols.append(types, ignore_index=True)\\n    try:\\n        pd.read_parquet(newpath)\\n        print(\"Succes with {}\".format(i))\\n    except ArrowInvalid:\\n        print(\"Failure with {}. Replacing\".format(i))\\n        \\ncols\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pyarrow import ArrowInvalid\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "cols = pd.DataFrame()\n",
    "newpath = '/h/dsmith/physionet_data/preppedg/physionet_data.parquet'\n",
    "\n",
    "for i in os.listdir(fin):\n",
    "    fullpath = os.path.join(fin, i)\n",
    "    df = pd.read_parquet(fullpath)\n",
    "    df[\"SepsisEver\"] = df[\"SepsisEver\"].replace(0.1, 1).astype(int)\n",
    "    table = pa.table(df)\n",
    "    pq.write_to_dataset(table, newpath)\n",
    "    types = df.dtypes.to_dict()\n",
    "    types[\"file\"] = i\n",
    "    cols = cols.append(types, ignore_index=True)\n",
    "    try:\n",
    "        pd.read_parquet(newpath)\n",
    "        print(\"Succes with {}\".format(i))\n",
    "    except ArrowInvalid:\n",
    "        print(\"Failure with {}. Replacing\".format(i))\n",
    "        \n",
    "cols\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "formed-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "badcols = [\"ICULOS\", \"SepsisLabel\", \"SepsisEver\", \"index\"]\n",
    "slim = df[[i for i in df.columns if i not in badcols]]\n",
    "variations = slim.groupby(\"id\").std().mean()\n",
    "static_vars = variations[variations == 0].index.tolist()\n",
    "puny_vars = variations[(0 < variations) & (variations < 0.05)].index.tolist()\n",
    "moving_vars = [i for i in variations.index.tolist() if i not in puny_vars + static_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "obvious-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groups = {\n",
    "    \"earlymean\": slim[moving_vars + [\"id\"]].groupby(\"id\").head(npts).groupby(\"id\").mean().reset_index(),\n",
    "    \"earlystd\": slim[moving_vars + [\"id\"]].groupby(\"id\").head(npts).groupby(\"id\").std().reset_index(),\n",
    "    \"labels\": df.groupby(\"id\")[\"SepsisEver\"].tail(1),\n",
    "    \"skew\": slim[moving_vars + [\"id\"]].groupby(\"id\").tail(npts).groupby(\"id\").skew().reset_index(),\n",
    "    \"std\": slim[moving_vars + [\"id\"]].groupby(\"id\").tail(npts).groupby(\"id\").std().reset_index(),\n",
    "    \"mean\": slim[moving_vars + [\"id\"]].groupby(\"id\").tail(npts).groupby(\"id\").mean().reset_index(),\n",
    "    \"static\": slim[static_vars + [\"id\"]].groupby(\"id\").tail(1).reset_index()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fifty-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_std</th>\n",
       "      <th>O2Sat_std</th>\n",
       "      <th>Temp_std</th>\n",
       "      <th>SBP_std</th>\n",
       "      <th>MAP_std</th>\n",
       "      <th>DBP_std</th>\n",
       "      <th>Resp_std</th>\n",
       "      <th>EtCO2_std</th>\n",
       "      <th>BaseExcess_std</th>\n",
       "      <th>HCO3_std</th>\n",
       "      <th>...</th>\n",
       "      <th>Hgb_earlystd</th>\n",
       "      <th>PTT_earlystd</th>\n",
       "      <th>WBC_earlystd</th>\n",
       "      <th>Fibrinogen_earlystd</th>\n",
       "      <th>Platelets_earlystd</th>\n",
       "      <th>Age_static</th>\n",
       "      <th>Gender_static</th>\n",
       "      <th>Unit1_static</th>\n",
       "      <th>Unit2_static</th>\n",
       "      <th>HospAdmTime_static</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.055505</td>\n",
       "      <td>1.012423</td>\n",
       "      <td>0.124601</td>\n",
       "      <td>20.773932</td>\n",
       "      <td>9.890310</td>\n",
       "      <td>4.761244</td>\n",
       "      <td>2.006240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.107026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.378354</td>\n",
       "      <td>63.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.852849</td>\n",
       "      <td>1.950071</td>\n",
       "      <td>0.193196</td>\n",
       "      <td>7.761908</td>\n",
       "      <td>6.290204</td>\n",
       "      <td>4.412419</td>\n",
       "      <td>3.162717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.204339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-72.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.593506</td>\n",
       "      <td>2.945807</td>\n",
       "      <td>0.179547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.104486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.044641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-52.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.655045</td>\n",
       "      <td>0.761942</td>\n",
       "      <td>0.376509</td>\n",
       "      <td>13.913323</td>\n",
       "      <td>7.333523</td>\n",
       "      <td>5.337498</td>\n",
       "      <td>3.093003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473984</td>\n",
       "      <td>6.824056</td>\n",
       "      <td>1.289315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.961526</td>\n",
       "      <td>78.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-134.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.828918</td>\n",
       "      <td>0.447989</td>\n",
       "      <td>0.145340</td>\n",
       "      <td>17.176103</td>\n",
       "      <td>14.045664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.717825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.943213</td>\n",
       "      <td>53.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36607</th>\n",
       "      <td>1.334375</td>\n",
       "      <td>0.579751</td>\n",
       "      <td>0.133229</td>\n",
       "      <td>2.536402</td>\n",
       "      <td>1.686548</td>\n",
       "      <td>1.817355</td>\n",
       "      <td>2.241651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.493997</td>\n",
       "      <td>41.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36608</th>\n",
       "      <td>3.362832</td>\n",
       "      <td>1.219188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.119508</td>\n",
       "      <td>10.141529</td>\n",
       "      <td>8.508529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36609</th>\n",
       "      <td>3.541814</td>\n",
       "      <td>1.932184</td>\n",
       "      <td>0.259821</td>\n",
       "      <td>7.004959</td>\n",
       "      <td>5.245104</td>\n",
       "      <td>4.141927</td>\n",
       "      <td>4.143268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492043</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36610</th>\n",
       "      <td>4.195235</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.073786</td>\n",
       "      <td>27.548745</td>\n",
       "      <td>14.704497</td>\n",
       "      <td>8.778762</td>\n",
       "      <td>1.779513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-12.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36611</th>\n",
       "      <td>3.771604</td>\n",
       "      <td>1.181160</td>\n",
       "      <td>0.240124</td>\n",
       "      <td>5.365132</td>\n",
       "      <td>7.620235</td>\n",
       "      <td>2.945807</td>\n",
       "      <td>1.932644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36612 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          HR_std  O2Sat_std  Temp_std    SBP_std    MAP_std   DBP_std  \\\n",
       "0       3.055505   1.012423  0.124601  20.773932   9.890310  4.761244   \n",
       "1       3.852849   1.950071  0.193196   7.761908   6.290204  4.412419   \n",
       "2      16.593506   2.945807  0.179547   0.000000   9.104486  0.000000   \n",
       "3       4.655045   0.761942  0.376509  13.913323   7.333523  5.337498   \n",
       "4       2.828918   0.447989  0.145340  17.176103  14.045664  0.000000   \n",
       "...          ...        ...       ...        ...        ...       ...   \n",
       "36607   1.334375   0.579751  0.133229   2.536402   1.686548  1.817355   \n",
       "36608   3.362832   1.219188  0.000000   9.119508  10.141529  8.508529   \n",
       "36609   3.541814   1.932184  0.259821   7.004959   5.245104  4.141927   \n",
       "36610   4.195235   0.527046  0.073786  27.548745  14.704497  8.778762   \n",
       "36611   3.771604   1.181160  0.240124   5.365132   7.620235  2.945807   \n",
       "\n",
       "       Resp_std  EtCO2_std  BaseExcess_std  HCO3_std  ...  Hgb_earlystd  \\\n",
       "0      2.006240        0.0        0.421637  0.125008  ...      0.023784   \n",
       "1      3.162717        0.0        0.000000  0.079057  ...      0.000000   \n",
       "2      2.044641        0.0        0.000000  0.237537  ...      0.000000   \n",
       "3      3.093003        0.0        0.000000  0.000000  ...      0.473984   \n",
       "4      3.717825        0.0        0.000000  0.000000  ...      0.065405   \n",
       "...         ...        ...             ...       ...  ...           ...   \n",
       "36607  2.241651        0.0        0.000000  0.000000  ...      0.287781   \n",
       "36608  0.000000        0.0        0.000000  0.000000  ...      0.000000   \n",
       "36609  4.143268        0.0        0.000000  0.000000  ...      0.000000   \n",
       "36610  1.779513        0.0        0.000000  0.000000  ...      0.000000   \n",
       "36611  1.932644        0.0        0.000000  0.000000  ...      0.000000   \n",
       "\n",
       "       PTT_earlystd  WBC_earlystd  Fibrinogen_earlystd  Platelets_earlystd  \\\n",
       "0          0.202160      0.107026                  0.0            2.378354   \n",
       "1          2.204339      0.000000                  0.0            0.000000   \n",
       "2          0.000000      0.000000                  0.0            0.000000   \n",
       "3          6.824056      1.289315                  0.0           18.961526   \n",
       "4          0.000000      0.081756                  0.0            2.943213   \n",
       "...             ...           ...                  ...                 ...   \n",
       "36607      0.000000      0.104648                  0.0            5.493997   \n",
       "36608      0.000000      0.000000                  0.0            0.000000   \n",
       "36609      0.000000      0.000000                  0.0            0.000000   \n",
       "36610      0.000000      0.000000                  0.0            0.000000   \n",
       "36611      0.000000      0.000000                  0.0            0.000000   \n",
       "\n",
       "       Age_static  Gender_static  Unit1_static  Unit2_static  \\\n",
       "0           63.18            0.0      0.492043      0.507957   \n",
       "1           58.67            1.0      0.000000      1.000000   \n",
       "2           76.16            0.0      0.492043      0.507957   \n",
       "3           78.63            1.0      0.000000      1.000000   \n",
       "4           53.62            1.0      1.000000      0.000000   \n",
       "...           ...            ...           ...           ...   \n",
       "36607       41.00            1.0      0.000000      1.000000   \n",
       "36608       46.00            0.0      0.492043      0.507957   \n",
       "36609       47.00            1.0      0.492043      0.507957   \n",
       "36610       59.00            0.0      0.000000      1.000000   \n",
       "36611       61.00            0.0      1.000000      0.000000   \n",
       "\n",
       "       HospAdmTime_static  \n",
       "0                   -0.02  \n",
       "1                  -72.06  \n",
       "2                  -52.14  \n",
       "3                 -134.72  \n",
       "4                   -0.05  \n",
       "...                   ...  \n",
       "36607                0.00  \n",
       "36608               -4.51  \n",
       "36609               -0.01  \n",
       "36610              -12.64  \n",
       "36611                0.00  \n",
       "\n",
       "[36612 rows x 165 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_sets = {\n",
    "    \"late\": [\"std\", \"mean\", \"static\", \"skew\"],\n",
    "    \"early\": [\"earlymean\", \"earlystd\", \"static\"],\n",
    "    \"static\": [\"static\"],\n",
    "    \"moving\": [\"mean\", \"std\", \"skew\"],\n",
    "    \"tail\": [\"mean\"],\n",
    "}\n",
    "\n",
    "var_sets[\"kitchen_sink\"] = var_sets[\"late\"] + var_sets[\"early\"]\n",
    "\n",
    "        \n",
    "def assemble_data(var_set):\n",
    "    chosen_sets = var_sets[var_set]\n",
    "\n",
    "    dataset = data_groups[chosen_sets[0]].copy()\n",
    "    dataset.columns = [\n",
    "        (i + \"_\" + chosen_sets[0]).replace(f\"id_{chosen_sets[0]}\", \"id\")\n",
    "        for i in dataset.columns\n",
    "    ]\n",
    "    \n",
    "    for i in range(1, len(chosen_sets)):\n",
    "        dataset = dataset.merge(\n",
    "            data_groups[chosen_sets[i]], on=\"id\", suffixes=(\"\", \"_\" + chosen_sets[i])\n",
    "        )\n",
    "    \n",
    "    del dataset[\"id\"]\n",
    "    for i in dataset.columns:\n",
    "        if \"index\" in i:\n",
    "            del dataset[i]\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "assemble_data(\"kitchen_sink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "marine-calgary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing late...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5839168999227393 +/- 0.2116174621477832 on late.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.5817868715530924 +/- 0.2051878102477961 on late.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5763242413316086 +/- 0.194665042818923 on late.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.585802772101047 +/- 0.20175314575051811 on late.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.5903115947077339 +/- 0.2204703558668445 on late.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6183317716626058 +/- 0.2064032958121587 on late.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.6166366639908667 +/- 0.18356403097792412 on late.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.6136072564953543 +/- 0.20620080918022354 on late.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.5989394090156612 +/- 0.20747395028876 on late.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.6067801472440925 +/- 0.22677478152452527 on late.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.6814211332910953 +/- 0.16707953890802948 on late.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.6660715311329912 +/- 0.17068149509503538 on late.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.6841820458040686 +/- 0.1752872179539038 on late.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.6688042410809855 +/- 0.180387759227451 on late.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.6557773711450092 +/- 0.19387419679878193 on late.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.7580329199493204 +/- 0.1310659010347461 on late.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.7582790900767996 +/- 0.1354500626081851 on late.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.7550567176630106 +/- 0.13554931919790783 on late.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.7272809132111377 +/- 0.15687868840055674 on late.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.6948320608489172 +/- 0.177090174495882 on late.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.8593079429193811 +/- 0.08807651612566317 on late.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.8516321535198157 +/- 0.10449409555014762 on late.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.8269148169160492 +/- 0.11942701677179682 on late.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.792391297050956 +/- 0.13833713230905512 on late.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.7330973547172575 +/- 0.16174328659588727 on late.\n",
      "\n",
      "Preparing early...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5412027017773807 +/- 0.23956721710078305 on early.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.5688976877178689 +/- 0.23646239002366934 on early.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5681312283772255 +/- 0.22538765463358296 on early.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.5532194410178523 +/- 0.21484423550951137 on early.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.580313960709747 +/- 0.22384213951201767 on early.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6016986059534041 +/- 0.20963075179602975 on early.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.5758594099525144 +/- 0.21004089398915643 on early.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.5891353590348383 +/- 0.2342972814861251 on early.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.5791107905057382 +/- 0.2223545405592896 on early.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.5924409965194707 +/- 0.22360572845150956 on early.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.6534547582672452 +/- 0.1902752693066903 on early.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.6635877809869808 +/- 0.19137565157338465 on early.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.6478552997326239 +/- 0.19382292682259425 on early.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.649359456422226 +/- 0.19441219656094322 on early.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.6400182238843577 +/- 0.208090673152814 on early.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.7534174407764782 +/- 0.14234612963487842 on early.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.7446776441601596 +/- 0.14325212972809023 on early.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.7296282005361248 +/- 0.15666480040957234 on early.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.7073139149113473 +/- 0.17278334352781582 on early.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.6910089834978073 +/- 0.1771921891528694 on early.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.8481635363883203 +/- 0.08748659136460267 on early.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.8414720918426486 +/- 0.10745378870792821 on early.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.8257939868640642 +/- 0.12523477215236808 on early.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.7818770884331295 +/- 0.14604599307859623 on early.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.732224179138277 +/- 0.1662124484067912 on early.\n",
      "\n",
      "Preparing static...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.6327138416040718 +/- 0.26349675803215605 on static.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.6102601170081979 +/- 0.23962128307434538 on static.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.6251737989593469 +/- 0.24073668880433835 on static.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.6049072015521928 +/- 0.2387372184911485 on static.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.6125008521933479 +/- 0.23910802113087376 on static.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.5970127807371035 +/- 0.24770659983136775 on static.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.6003996022252353 +/- 0.246554781491427 on static.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.6181522031491695 +/- 0.24139027427771992 on static.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.5724572303365616 +/- 0.23601912300947228 on static.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.594415638527404 +/- 0.22571527629294555 on static.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.5607134540332502 +/- 0.2617092866394431 on static.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.573494392530475 +/- 0.24525132081101128 on static.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.5581458271765316 +/- 0.25914880663399087 on static.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.5650832479150913 +/- 0.24789421105338028 on static.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.5517519603430613 +/- 0.22199879105242418 on static.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.5773202073429304 +/- 0.2610444714023836 on static.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.5778920085671351 +/- 0.24900902924802829 on static.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.5819893019712258 +/- 0.2502296334703032 on static.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.5733030835152466 +/- 0.2412791981923655 on static.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.5586333638208456 +/- 0.2155159109998211 on static.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.6278188653901495 +/- 0.24885318950714153 on static.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.6294054144449345 +/- 0.250273883844304 on static.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.615392103669675 +/- 0.2452103067972391 on static.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.5838162777059804 +/- 0.22575257902475865 on static.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.5459335869500519 +/- 0.21933237100371467 on static.\n",
      "\n",
      "Preparing moving...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5894891777784971 +/- 0.19563833106742184 on moving.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.5771999977324571 +/- 0.19326702598884085 on moving.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5744408903029871 +/- 0.18769057099170128 on moving.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.5921942744243088 +/- 0.18559560864779878 on moving.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.5988052883277781 +/- 0.19388165307446947 on moving.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6299141720089432 +/- 0.18754692541243495 on moving.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.6048655429101915 +/- 0.16517121575668317 on moving.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.5992394705824349 +/- 0.1709795265025899 on moving.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.6200821059387098 +/- 0.1871049282080843 on moving.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.6072709434813437 +/- 0.1806837687608906 on moving.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.7132986245114527 +/- 0.12654270478441781 on moving.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.7198806824886462 +/- 0.1256036941234129 on moving.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.7055695851485487 +/- 0.1258911347430958 on moving.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.7007078687170228 +/- 0.14431507364135526 on moving.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.6795416609542985 +/- 0.15326414683771053 on moving.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.8095752295402361 +/- 0.07687294228522738 on moving.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.80618779641224 +/- 0.07461051712298951 on moving.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.7854305071941529 +/- 0.08219239199723213 on moving.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.7590211061999248 +/- 0.11150384735101523 on moving.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.7273643349214588 +/- 0.12866573585069643 on moving.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.8963740795379463 +/- 0.023030380931864443 on moving.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.8914578600272612 +/- 0.026538239344596242 on moving.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.8786478984725562 +/- 0.0334151906704991 on moving.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.8328452099125638 +/- 0.06647707817386042 on moving.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.7880264261241232 +/- 0.09370637572699929 on moving.\n",
      "\n",
      "Preparing tail...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5589287262032933 +/- 0.2032786862227184 on tail.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.577933249503863 +/- 0.17850066258677344 on tail.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5545266944251712 +/- 0.1921605268986054 on tail.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.5603163207445416 +/- 0.1827381735082301 on tail.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.5529162317434824 +/- 0.18305658076884837 on tail.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6162570743236419 +/- 0.1848007565321553 on tail.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.610821415928385 +/- 0.18535253969501886 on tail.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.5955516849857779 +/- 0.19668101497663099 on tail.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.5936413322948384 +/- 0.18990779861737966 on tail.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.5931786043601568 +/- 0.20049967076409536 on tail.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.6907106524243092 +/- 0.1468668309307792 on tail.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.6772184811908062 +/- 0.1444872025370654 on tail.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.6756619547025483 +/- 0.1588221385759616 on tail.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.669707424308448 +/- 0.15638138805653604 on tail.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.6556691705611467 +/- 0.1664159994630512 on tail.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.7847484168597185 +/- 0.09519980985402017 on tail.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.7688250219183382 +/- 0.10575180139394338 on tail.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.7533655707323462 +/- 0.11069394693306696 on tail.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.722038518095067 +/- 0.1292958566100451 on tail.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.7005434643968165 +/- 0.14213584479258462 on tail.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.8839748341523588 +/- 0.032927509295600295 on tail.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.87567110692345 +/- 0.03524162422021922 on tail.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.8550508399530917 +/- 0.05046845982306807 on tail.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.7977483448055589 +/- 0.08170351079206416 on tail.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.743478196008498 +/- 0.11310926584563287 on tail.\n",
      "\n",
      "Preparing kitchen_sink...\n",
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5832906329144892 +/- 0.23531075629753195 on kitchen_sink.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.5890263081223834 +/- 0.22920418132018275 on kitchen_sink.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5933409872852007 +/- 0.22150705410107774 on kitchen_sink.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.5707268787823772 +/- 0.23893760705677966 on kitchen_sink.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.5905847217433944 +/- 0.23079483346935303 on kitchen_sink.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6101386095277679 +/- 0.23031917572081956 on kitchen_sink.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.6001402892996888 +/- 0.21640601905556284 on kitchen_sink.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.614890529144565 +/- 0.2386507607742108 on kitchen_sink.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.6311708532420865 +/- 0.22749678513486876 on kitchen_sink.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.6166397893213945 +/- 0.2255864613398103 on kitchen_sink.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.6812584296280737 +/- 0.18379055314972315 on kitchen_sink.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.6804665275608652 +/- 0.19124325254813748 on kitchen_sink.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.6686681512110992 +/- 0.19644961427183638 on kitchen_sink.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.6697605027142639 +/- 0.1854590736570541 on kitchen_sink.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.6605844726120349 +/- 0.207353045951237 on kitchen_sink.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.7781071864551307 +/- 0.1311233969824927 on kitchen_sink.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.7631672487439379 +/- 0.15722924084075063 on kitchen_sink.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.756010652081194 +/- 0.14861973992410554 on kitchen_sink.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.7332897452907832 +/- 0.16735270556559004 on kitchen_sink.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.6987942638921688 +/- 0.1922168103584681 on kitchen_sink.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.8587606445848763 +/- 0.10775521254208625 on kitchen_sink.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.8535710444317575 +/- 0.113588517594547 on kitchen_sink.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.8377842018196733 +/- 0.12608407824205936 on kitchen_sink.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.8015686101050962 +/- 0.14755804689742208 on kitchen_sink.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.7548386232971238 +/- 0.1642117624891914 on kitchen_sink.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "class BoostModel(object):\n",
    "    \n",
    "    def __init__(self, X, y, group=\"none\", nparts=10):\n",
    "        self.Xdata = X\n",
    "        self.ydata = y\n",
    "        self.nparts = nparts\n",
    "        self.results = pd.DataFrame()\n",
    "        self.dgroup = group\n",
    "        \n",
    "    def optimize(self):\n",
    "        depths = [2, 3, 5, 10]\n",
    "        min_leafs = [2, 8, 32, 128]\n",
    "        \n",
    "        for i in depths:\n",
    "            for j in min_leafs:\n",
    "                model = RFC(max_depth=i, min_samples_leaf=j, class_weight=\"balanced\")\n",
    "                cv_results = cross_validate(model, self.Xdata, self.ydata, cv=self.nparts, scoring=(\"f1\", \"accuracy\"))\n",
    "                self.results = self.results.append(\n",
    "                    {\n",
    "                        \"depth\": i,\n",
    "                        \"min_leafs\": j,\n",
    "                        \"data_group\": self.dgroup,\n",
    "                        \"test_acc\": cv_results[\"test_accuracy\"].mean(),\n",
    "                        \"test_acc_std\": cv_results[\"test_accuracy\"].std(),\n",
    "                        \"test_f1\": cv_results[\"test_accuracy\"].mean(),\n",
    "                        \"test_f1_std\": cv_results[\"test_accuracy\"].std(),\n",
    "                    },\n",
    "                    ignore_index=True\n",
    "                )\n",
    "                print(\n",
    "                    \"Random Forest with depth {} and min_leafs {} got accuracy = {} +/- {} with f1 = {} on {}.\".format(\n",
    "                        i, j, \n",
    "                        cv_results[\"test_accuracy\"].mean(), cv_results[\"test_accuracy\"].std(),\n",
    "                        cv_results[\"test_f1\"]\n",
    "                        self.dgroup\n",
    "                    )\n",
    "                )\n",
    "\n",
    "\n",
    " \n",
    "all_results = pd.DataFrame()\n",
    "for i in var_sets:\n",
    "    print(\"\\nPreparing {}...\".format(i))\n",
    "    xdata = assemble_data(i)\n",
    "    print(\"Data prepped. Running models.\")\n",
    "    BM = BoostModel(xdata, data_groups[\"labels\"], group=i)\n",
    "    BM.optimize()\n",
    "    all_results = all_results.append(BM.results, ignore_index=True)\n",
    "    all_results.to_csv(\"model_opt_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "interstate-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
       "                       min_samples_leaf=5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_data = assemble_data(\"late\")\n",
    "late_model = RFC(max_depth=10, min_samples_leaf=5, class_weight=\"balanced\")\n",
    "late_model.fit(late_data, data_groups[\"labels\"])\n",
    "\n",
    "early_data = assemble_data(\"early\")\n",
    "early_model = RFC(max_depth=10, min_samples_leaf=5, class_weight=\"balanced\")\n",
    "early_model.fit(early_data, data_groups[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "abstract-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late:\n",
      "       feature            importance\n",
      "0    Platelets  0.023320114880305807\n",
      "1    Temp_skew   0.02145039735667789\n",
      "2         Temp  0.020937590173274012\n",
      "3          SBP   0.02085242318912929\n",
      "4       HR_std  0.020743057655751875\n",
      "5           HR  0.020602718989273558\n",
      "6      MAP_std  0.020384448805610106\n",
      "7      Calcium  0.020152801476564477\n",
      "8     Temp_std  0.020141826136118413\n",
      "9          Hct  0.019833759065901128\n",
      "10         WBC  0.019770599361059536\n",
      "11     Glucose   0.01972158767116206\n",
      "12   Magnesium   0.01951566706671687\n",
      "13        Resp  0.019000566190767808\n",
      "14    DBP_skew  0.018939093392486974\n",
      "15         MAP  0.018832892776411956\n",
      "16   O2Sat_std  0.018200966230095674\n",
      "17  O2Sat_skew    0.0176704313598073\n",
      "18   Potassium  0.017471725799557032\n",
      "19    MAP_skew   0.01738108992433526\n",
      "\n",
      "early:\n",
      "                 feature            importance\n",
      "0    Potassium_earlymean  0.029773307779178665\n",
      "1      Calcium_earlymean   0.02639284562018768\n",
      "2         Temp_earlymean   0.02575718271635078\n",
      "3           HR_earlymean  0.025023833007323564\n",
      "4          BUN_earlymean  0.024844595049871118\n",
      "5    Platelets_earlymean   0.02404259932105595\n",
      "6          DBP_earlymean   0.02314326424536317\n",
      "7                   Resp  0.023047981342201762\n",
      "8                   Temp  0.022983007913494603\n",
      "9                    SBP  0.022672724921238993\n",
      "10         WBC_earlymean  0.022429673000594282\n",
      "11     Glucose_earlymean  0.022193787781174597\n",
      "12  Creatinine_earlymean  0.022056612755256784\n",
      "13                   MAP  0.021901125512472364\n",
      "14         MAP_earlymean  0.021896264114268534\n",
      "15                    HR   0.02175917951688814\n",
      "16        Resp_earlymean  0.021353969188664758\n",
      "17                   Age   0.02112536625358301\n",
      "18         Hct_earlymean  0.020907143364867223\n",
      "19   Magnesium_earlymean  0.020528969522676566\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features(model, data):\n",
    "    features = pd.DataFrame(\n",
    "        data=np.asarray([data.columns.tolist(), model.feature_importances_.tolist()]).T, \n",
    "        columns=[\"feature\", \"importance\"]\n",
    "    )\n",
    "    return features.sort_values(by=\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"late:\")\n",
    "print(get_features(late_model, late_data).head(20))\n",
    "\n",
    "print(\"\\nearly:\")\n",
    "print(get_features(early_model, early_data).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dependent-lodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepped. Running models.\n",
      "Random Forest with depth 2 and min_leafs 2 got accuracy = 0.5501025168085347 +/- 0.16610075239913497 on late.\n",
      "Random Forest with depth 2 and min_leafs 8 got accuracy = 0.5787804900607776 +/- 0.17618248025871305 on late.\n",
      "Random Forest with depth 2 and min_leafs 32 got accuracy = 0.5906648838607782 +/- 0.1841090159776819 on late.\n",
      "Random Forest with depth 2 and min_leafs 128 got accuracy = 0.5855578550893882 +/- 0.18923345223568977 on late.\n",
      "Random Forest with depth 2 and min_leafs 256 got accuracy = 0.5949539934936436 +/- 0.19787912369917937 on late.\n",
      "Random Forest with depth 3 and min_leafs 2 got accuracy = 0.6392799671086934 +/- 0.1660488633067135 on late.\n",
      "Random Forest with depth 3 and min_leafs 8 got accuracy = 0.622562566655692 +/- 0.14324658080683983 on late.\n",
      "Random Forest with depth 3 and min_leafs 32 got accuracy = 0.6156278087882504 +/- 0.16565692507454569 on late.\n",
      "Random Forest with depth 3 and min_leafs 128 got accuracy = 0.6074882098957064 +/- 0.17386293581218018 on late.\n",
      "Random Forest with depth 3 and min_leafs 256 got accuracy = 0.601916066302358 +/- 0.18283711803146205 on late.\n",
      "Random Forest with depth 5 and min_leafs 2 got accuracy = 0.7131070768074965 +/- 0.12526771171794854 on late.\n",
      "Random Forest with depth 5 and min_leafs 8 got accuracy = 0.7245520372008316 +/- 0.1291671872035568 on late.\n",
      "Random Forest with depth 5 and min_leafs 32 got accuracy = 0.7078630407064231 +/- 0.12576952654588278 on late.\n",
      "Random Forest with depth 5 and min_leafs 128 got accuracy = 0.6913670762614961 +/- 0.14730984763275806 on late.\n",
      "Random Forest with depth 5 and min_leafs 256 got accuracy = 0.677328531612308 +/- 0.14862656759152623 on late.\n",
      "Random Forest with depth 7 and min_leafs 2 got accuracy = 0.81918919378556 +/- 0.06665367849894788 on late.\n",
      "Random Forest with depth 7 and min_leafs 8 got accuracy = 0.8153101215507428 +/- 0.0733799561715467 on late.\n",
      "Random Forest with depth 7 and min_leafs 32 got accuracy = 0.7973122381230353 +/- 0.07837545047002648 on late.\n",
      "Random Forest with depth 7 and min_leafs 128 got accuracy = 0.7663664981872337 +/- 0.1032363607046046 on late.\n",
      "Random Forest with depth 7 and min_leafs 256 got accuracy = 0.7317086040274845 +/- 0.12490742459663344 on late.\n",
      "Random Forest with depth 10 and min_leafs 2 got accuracy = 0.9025465029043197 +/- 0.019156082745263762 on late.\n",
      "Random Forest with depth 10 and min_leafs 8 got accuracy = 0.8986684749326861 +/- 0.02301338390417921 on late.\n",
      "Random Forest with depth 10 and min_leafs 32 got accuracy = 0.885667510182685 +/- 0.027779761724236386 on late.\n",
      "Random Forest with depth 10 and min_leafs 128 got accuracy = 0.8420229033768637 +/- 0.056784568577266124 on late.\n",
      "Random Forest with depth 10 and min_leafs 256 got accuracy = 0.789883894343838 +/- 0.09450869276255297 on late.\n"
     ]
    }
   ],
   "source": [
    "xdata = assemble_data(\"late\")\n",
    "print(\"Data prepped. Running models.\")\n",
    "BM = BoostModel(xdata, data_groups[\"labels\"], group=\"late\")\n",
    "BM.optimize()\n",
    "all_results = all_results.append(BM.results, ignore_index=True)\n",
    "all_results.to_csv(\"model_opt_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "forecasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
